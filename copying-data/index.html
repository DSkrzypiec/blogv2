<!DOCTYPE html><html lang="en" data-astro-cid-gvpn4u4b> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Copying data between distributed systems</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.26/dist/katex.min.css" crossorigin="anonymous"><style>*,*:before,*:after{box-sizing:border-box}html,body{max-width:100%;overflow-x:hidden}html{-webkit-text-size-adjust:100%}:root{--bg-color: #111010;--text-primary: #ffe9c6;--text-secondary: #2AA198;--accent-color: #f97d43;--font-body: "Roboto", sans-serif;--font-code: "JetBrains Mono", monospace}html{font-size:19px}@media (max-width: 480px){html{font-size:16px}}@media (max-width: 360px){html{font-size:15px}}body{font-size:1rem;line-height:1.66;background-color:var(--bg-color);color:var(--text-primary);font-family:var(--font-body);margin:0;padding:0;word-wrap:break-word;overflow-wrap:break-word}h1{font-size:2.25rem;line-height:1.2}h2{font-size:1.75rem;line-height:1.3}h3{font-size:1.35rem;line-height:1.35}@media (max-width: 768px){h1{font-size:2rem}h2{font-size:1.5rem}h3{font-size:1.2rem}}@media (max-width: 480px){h1{font-size:1.75rem}h2{font-size:1.35rem}h3{font-size:1.1rem}}@media (max-width: 360px){h1{font-size:1.6rem}h2{font-size:1.25rem}h3{font-size:1.05rem}}a{color:var(--text-secondary);text-decoration:none}a:hover{text-decoration:underline}pre{background-color:#1e1e1e;border-radius:8px;padding:1rem;overflow-x:auto;margin:1rem 0;font-size:15px;font-family:var(--font-code)}code{background-color:transparent}pre>code{display:block}.toc ul{list-style:none;margin:0;padding:0}.toc li{margin:.5rem 0}.toc a{color:var(--text-secondary);text-decoration:none}.toc a:hover{text-decoration:underline}.toc a.active{font-weight:700;color:var(--accent-color)}nav[data-astro-cid-dmqpwcec]{padding:1rem 0;text-align:center}ul[data-astro-cid-dmqpwcec]{list-style:none;padding:0;margin:0;display:flex;justify-content:center;gap:1.5rem;flex-wrap:wrap}@media (max-width: 480px){ul[data-astro-cid-dmqpwcec]{gap:1rem}a[data-astro-cid-dmqpwcec]{font-size:1rem;padding:.4rem .8rem}}@media (max-width: 360px){ul[data-astro-cid-dmqpwcec]{gap:.5rem}a[data-astro-cid-dmqpwcec]{font-size:.9rem;padding:.3rem .6rem}}li[data-astro-cid-dmqpwcec]{display:inline}a[data-astro-cid-dmqpwcec]{color:var(--text-primary);font-size:1.2rem;padding:.5rem 1rem;border:1px solid transparent;transition:all .3s ease-in-out}a[data-astro-cid-dmqpwcec]:hover{border:1px solid var(--accent-color);border-radius:4px;color:var(--accent-color)}.active[data-astro-cid-dmqpwcec] a[data-astro-cid-dmqpwcec]{color:var(--accent-color);font-weight:700;border-bottom:2px solid var(--accent-color)}hr[data-astro-cid-dmqpwcec]{margin-top:1rem;border:none;height:2px;background:var(--text-secondary);width:90%;max-width:800px;margin-left:auto;margin-right:auto}
.post-title[data-astro-cid-resui2ln]{margin-bottom:2rem}.post-title[data-astro-cid-resui2ln] h1[data-astro-cid-resui2ln]{font-size:1.75rem;color:var(--accent-color);margin:0}.post-date[data-astro-cid-resui2ln]{font-size:1rem;color:var(--text-secondary);margin-top:.5rem}.publish-label[data-astro-cid-resui2ln]{font-weight:700;color:var(--text-primary)}
.chapter[data-astro-cid-5d3zeytc]{font-size:2rem;margin-top:2rem;color:var(--accent-color)}.chapter[data-astro-cid-5d3zeytc] a[data-astro-cid-5d3zeytc]{color:var(--accent-color);text-decoration:none}.chapter[data-astro-cid-5d3zeytc] a[data-astro-cid-5d3zeytc]:hover{text-decoration:underline}
.post-layout{display:flex;flex-direction:row}@media (min-width: 1024px){.post-layout{flex-direction:row}.post-layout-sidebar{position:fixed;left:2rem;top:10rem;width:200px;font-size:.85rem;padding:1rem;z-index:10}.post-layout-content{flex:1;max-width:1000px;margin:0 auto;padding-left:240px;padding-right:2rem}}@media (min-width: 1400px){.post-layout-content{max-width:1200px}}.post-layout-sidebar{display:none}@media (min-width: 1024px){.post-layout-sidebar{display:block}}@media (max-width: 1023px){.post-layout{flex-direction:column}.post-layout-content{width:100%;max-width:100%}}:global(pre){width:100%!important;max-width:100%!important;overflow-x:auto;box-sizing:border-box}:global(.astro-code){width:100%!important;max-width:100%!important;box-sizing:border-box}:global(.astro-code pre){width:100%!important;max-width:100%!important;overflow-x:auto;box-sizing:border-box}:global(.post-layout-content pre){max-width:100%!important;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap}main[data-astro-cid-gvpn4u4b]{padding:2rem 1rem;max-width:900px;margin:0 auto;width:100%;box-sizing:border-box}@media (min-width: 1024px){main[data-astro-cid-gvpn4u4b]{padding:2rem 0;max-width:none}}@media (max-width: 768px){main[data-astro-cid-gvpn4u4b]{padding:1.5rem .75rem}}@media (max-width: 480px){main[data-astro-cid-gvpn4u4b]{padding:1rem .5rem}}article[data-astro-cid-gvpn4u4b]{max-width:800px;width:100%;margin:0 auto;color:var(--text-primary);box-sizing:border-box;word-wrap:break-word;overflow-wrap:break-word}h1[data-astro-cid-gvpn4u4b],h2[data-astro-cid-gvpn4u4b],h3[data-astro-cid-gvpn4u4b]{color:var(--accent-color);margin-top:1.5rem;word-wrap:break-word;overflow-wrap:break-word}p[data-astro-cid-gvpn4u4b]{color:var(--text-secondary);word-wrap:break-word;overflow-wrap:break-word;hyphens:auto}img[data-astro-cid-gvpn4u4b]{max-width:100%;max-height:400px;width:auto;height:auto;border-radius:8px;margin:1rem 0;object-fit:contain}@media (max-width: 768px){img[data-astro-cid-gvpn4u4b]{max-height:300px}}@media (max-width: 480px){img[data-astro-cid-gvpn4u4b]{max-height:250px}}blockquote[data-astro-cid-gvpn4u4b]{border-left:4px solid var(--accent-color);padding-left:1rem;color:var(--text-primary);font-style:italic;margin:1rem 0}code[data-astro-cid-gvpn4u4b]{font-family:monospace;background:#ffffff1a;padding:.2rem .4rem;border-radius:4px;font-size:.95rem}
</style></head> <body data-astro-cid-gvpn4u4b> <header data-astro-cid-gvpn4u4b> <nav data-astro-cid-dmqpwcec> <ul data-astro-cid-dmqpwcec> <li class data-astro-cid-dmqpwcec> <a href="/" data-astro-cid-dmqpwcec>Posts</a> </li><li class data-astro-cid-dmqpwcec> <a href="/about" data-astro-cid-dmqpwcec>About</a> </li><li class data-astro-cid-dmqpwcec> <a href="/resume.html" data-astro-cid-dmqpwcec>Resume</a> </li> </ul> </nav>  </header> <!-- 
      1) Wrap sidebar + main in a single parent .post-layout
         so flexbox can place them side by side on large screens 
    --> <div class="post-layout" data-astro-cid-gvpn4u4b> <!-- SIDEBAR --> <aside class="post-layout-sidebar" data-astro-cid-gvpn4u4b> <!-- The nav container that will hold our generated TOC --><nav id="table-of-contents" class="toc"></nav> <script client:load>
  window.addEventListener('DOMContentLoaded', () => {
    buildTOC();
    highlightActiveHeading();
  });

  // 1. Build the TOC once the page is loaded
  function buildTOC() {
    const chapterHeadings = Array.from(document.querySelectorAll('h2.chapter[id]'));
    const tocContainer = document.getElementById('table-of-contents');
    if (!tocContainer) return;

    const ul = document.createElement('ul');

    chapterHeadings.forEach((heading) => {
      const li = document.createElement('li');
      const a = document.createElement('a');

      // The heading has an `id` like "intro" or "symptoms"
      a.href = `#${heading.id}`;

      a.textContent = heading.textContent.trim();

      li.appendChild(a);
      ul.appendChild(li);
    });

    tocContainer.appendChild(ul);
  }

    function highlightActiveHeading() {
      const links = Array.from(document.querySelectorAll('#table-of-contents a'));
      const headingEls = links.map((link) => document.getElementById(link.hash.slice(1)));

      // 3. Create the observer
      const observer = new IntersectionObserver(
        (entries) => {
          entries.forEach((entry) => {
            console.log(
              `Heading: ${entry.target.id}, isIntersecting: ${entry.isIntersecting}`
            );
            if (entry.isIntersecting) {
              // Remove 'active' from all links
              links.forEach((l) => l.classList.remove('active'));

              // Highlight the link for the heading that just entered
              const activeLink = links.find(
                (l) => l.hash === `#${entry.target.id}`
              );
              if (activeLink) {
                activeLink.classList.add('active');
              }
            }
          });
        },
        {
          root: null,
          rootMargin: '-15% 0px -60% 0px',
          threshold: 0,
        }
      );

      // 4. Observe each heading
      headingEls.forEach((el) => {
        if (el) {
          console.log(`Observing heading: ${el.id}`);
          observer.observe(el);
        }
      });
    }
</script> </aside> <!-- MAIN CONTENT AREA --> <div class="post-layout-content" data-astro-cid-gvpn4u4b> <main data-astro-cid-gvpn4u4b> <article data-astro-cid-gvpn4u4b>  <div class="post-title" data-astro-cid-resui2ln> <h1 data-astro-cid-resui2ln>Copying data between distributed systems</h1> <p class="post-date" data-astro-cid-resui2ln> <span class="publish-label" data-astro-cid-resui2ln>Publish date:</span> 2022-06-05 </p> </div>  <h2 id="intro" class="chapter" data-astro-cid-5d3zeytc> <a href="#intro" data-astro-cid-5d3zeytc>Intro</a> </h2>  <p>
Transforming data from one form into another is the primary task of every
    programmer. For data engineers very common task is to move or copy data
    between two or more data sources with
<a href="https://en.wikipedia.org/wiki/Extract,_transform,_load">ETL</a> or
<a href="https://en.wikipedia.org/wiki/Extract,_load,_transform">ELT</a> processes.
    Usually implementation of those processes are very high level. Glueing few
    libraries into a script, or some
<a href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html">operators</a>
into a DAG in Python. Although not always. There are more interesting cases.
    Recently I've had one and I wanted to write a bit about this particular
    problem and possible solutions.
</p> <h2 id="the-problem" class="chapter" data-astro-cid-5d3zeytc> <a href="#the-problem" data-astro-cid-5d3zeytc>The problem</a> </h2>  <p>
The main problem was to copy rather large amount of data from very legacy
    database (Apache Cassandra 2.1) located on premise data center into
    cloud-based <a href="https://www.snowflake.com">Snowflake</a>.
</p> <h2 id="constrains" class="chapter" data-astro-cid-5d3zeytc> <a href="#constrains" data-astro-cid-5d3zeytc>Constrains</a> </h2>  <p>
The table which shall be copied doesn't have any event time stamps or dates.
    Partition is based on <code>user_id</code> column and clustering on UUID column. Table is
    rather big (surely > 1TB) but I don't know exactly because <code>SELECT COUNT(*)
    FROM ...</code> on Cassandra haven't succeeded in few hours. Therefore using builtin
    Cassandra's <code>COPY TO</code> is a bit risky in terms of capacity of local storage. Also
    it cannot be deterministically resumed once it's halted. Also data format
    should be suitable for Snowflake. This should be one time migration. It will
    not be a cyclical process. We must not oversaturate Cassandra cluster.
</p> <h2 id="high-level-solution" class="chapter" data-astro-cid-5d3zeytc> <a href="#high-level-solution" data-astro-cid-5d3zeytc>High level solution</a> </h2>  <p>
In consideration to the above constrains I decided to sketch custom copying
    program in Go which would connect to Cassandra (using <code>gocql</code> library), connect
    to Snowflake and somehow efficiently copy the data with extra schema
    validation.
</p> <p>
After initial testing it was clear that Cassandra responses very quickly and
    consistently for queries of the form
</p> <pre class="astro-code dark-plus" style="background-color:#1E1E1E;color:#D4D4D4; overflow-x: auto;" tabindex="0" data-language="sql"><code><span class="line"><span style="color:#569CD6">SELECT</span><span style="color:#D4D4D4"> * </span><span style="color:#569CD6">FROM</span><span style="color:#D4D4D4"> ... </span><span style="color:#569CD6">WHERE</span><span style="color:#D4D4D4"> user_id = $id</span></span></code></pre> <p>
That's great, because we already have (in Snowflake) a set of all existing
<code>user_id</code> values. The upside of this approach is that we can stop and resume
    copying as we like because we know what <code>user_ids</code> have been already copied.
    Also this program doesn't require much disk space (just for the binary) and RAM
    (configurable by copying parameters).
</p> <p>
The downside is possible many rather small requests to Cassandra which in
    general could be (and almost always is) slower than using native <code>COPY TO</code>. But
    in light of the constrains it is a necessary cost that we have to pay.
</p> <p>
Let's outline high level phases of the algorithm:
</p> <ol> <li>Get a set of <code>user_id</code> values that shall be copied</li> <li>Send a bunch of concurrent calls to Cassandra, one for each <code>user_id</code></li> <li>Asynchronously deserialize data and put it in a shared collection</li> <li>Start sending batched <code>INSERT INTO</code> statements into Snowflake concurrently</li> <li>Wait before another batch of aync calls to Cassandra only when number of
        goroutines responsible for sending data to Snowflake reaches its limit</li> <li>Repeat</li> </ol> <p>
One can notice that there are two degrees of concurrency in this algorithm. In
    order to provide efficient solution those degrees have to be set appropriately.
</p> <h2 id="concurrency-optimization" class="chapter" data-astro-cid-5d3zeytc> <a href="#concurrency-optimization" data-astro-cid-5d3zeytc>Concurrency optimization</a> </h2>  <p>
Naturally we should start our optimization with exploration of reasonable limits
    of the load that our end systems, Cassandra and Snowflake, could take including
    the constrains. On the Cassandra end few tests was enough to determine how many
    concurrent requests per seconds could be sent to not oversaturate the cluster.
    On the Snowflake end one of limitations was limit of queued queries for
    particular <a href="https://docs.snowflake.com/en/user-guide/warehouses-overview.html">warehouse</a>.
    Also number of rows in <code>VALUES</code> in <code>INSERT INTO</code> statement has its upper bound.
    Since single batched <code>INSERT INTO</code> takes around 1-5 seconds in my case and there
    is upper bound for queued queries I could easily estimate inserting data into
    Snowflake safely and near maximum efficiency.
</p> <p>
Now we're getting into the most interesting part of the problem. How to
    integrate dynamics of two systems? For example let's say we would send to
    Cassandra as many as possible concurrent requests (including the constrains).
    It might turned out that inserting the data, which will be sent from Cassandra,
    to Snowflake would take significantly longer than Cassandra response. In this
    case traffic on the Cassandra clusters would be like: spike, long flat, spike,
    long flat, etc. It also requires much more memory for the program which is
    performing this copying in order to keep buffers for Cassandra response data.
</p> <p>
We could get the same (or better) efficiency with fewer concurrent requests to
    Cassandra if we minimize pauses between Snowflake's reaching its set limit and
    next batch of requests to Cassandra. This optimization is a bit familiar to
    classic <a href="https://en.wikipedia.org/wiki/Lotkaâ€“Volterra_equations">Lotka-Volterra equations</a>.
</p> <p>
In general rate of generating outputs by the producer to rate of transforming
    and inserting data by consumer is a crucial statistics to optimize.
</p> <h2 id="go-implementation" class="chapter" data-astro-cid-5d3zeytc> <a href="#go-implementation" data-astro-cid-5d3zeytc>Go implementation</a> </h2>  <p>
I wrote a program which implemented above algorithm in Go. It took around one
    office day (few hours really) including implementation and tests for
    concurrency optimization. That was really smooth! Mostly because of Go easy
    concurrency model (goroutines and channels) and Go standard library <a href="https://pkg.go.dev/sync">sync</a> for
    providing basic synchronization primitives.
</p> <p>
I cannot include code examples this time. What is the most important is a fact
    that it was very easy to write general patterns like:
</p> <ul> <li>send this <code>N</code> request concurrently</li> <li>in the meantime results are sent over the channel</li> <li>concurrently results are taken from channel and batched <code>INSERT INTO</code> are
      produced</li> <li>start sending asynchronous <code>INSERT</code>s into Snowflake</li> <li>if number of concurrent writers are reached its max than we wait</li> </ul> <p>
It was really easy to write correct concurrent algorithm based just on high
    level plan using Go.
</p> <h2 id="summary" class="chapter" data-astro-cid-5d3zeytc> <a href="#summary" data-astro-cid-5d3zeytc>Summary</a> </h2>  <p>
Copying data usually is not very excited task. In this particular case the
    constrains of the whole task and optimization aspect was rather interesting in
    my opinion. There are many Cassandra caveats and possible networking
    issues that was not mentioned here which also might be interesting.
</p> <p>
Also if you got a bit less restrictive constrains you should use Cassandra
    native <code>COPY TO</code> instead of writing custom concurrent program for moving data.
</p> <h2 id="references" class="chapter" data-astro-cid-5d3zeytc> <a href="#references" data-astro-cid-5d3zeytc>References</a> </h2>  <ol> <li><a href="https://en.wikipedia.org/wiki/Extract,_transform,_load">ETL</a></li> <li><a href="https://en.wikipedia.org/wiki/Extract,_load,_transform">ELT</a></li> <li><a href="https://github.com/gocql/gocql">gocql</a></li> </ol>  </article> </main> </div> </div>  <!-- Global styles for .post-layout and .post-layout-sidebar -->  </body></html>